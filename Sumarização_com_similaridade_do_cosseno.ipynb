{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPGfCKXebWbH"
      },
      "source": [
        "# Sumarização com similaridade do cosseno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8hjBnVEbbEq"
      },
      "source": [
        "## Preparação do texto de exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1LwWn7XbPRa"
      },
      "source": [
        "# importação das bibliotecas utilizadas\n",
        "import re # expressão regular\n",
        "import nltk # linguagem natural\n",
        "import string # texto\n",
        "import numpy as np # matemática\n",
        "import networkx as nx # gráfos\n",
        "from nltk.cluster.util import cosine_distance # parte do cosseno da nltk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U6buOn1eFhD",
        "outputId": "0bfee949-45f9-42c2-f86c-82696879b519"
      },
      "source": [
        "# Baixando os módulos do nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Syy9rgPemgJ",
        "outputId": "9eb3afaa-0d9c-4e35-d748-4820cf851fa2"
      },
      "source": [
        "# Pegando as stopwords em português\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "print(stopwords)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'às', 'até', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois', 'do', 'dos', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram', 'éramos', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estou', 'eu', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'formos', 'fosse', 'fossem', 'fôssemos', 'fui', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'haver', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'lhe', 'lhes', 'mais', 'mas', 'me', 'mesmo', 'meu', 'meus', 'minha', 'minhas', 'muito', 'na', 'não', 'nas', 'nem', 'no', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os', 'ou', 'para', 'pela', 'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando', 'que', 'quem', 'são', 'se', 'seja', 'sejam', 'sejamos', 'sem', 'ser', 'será', 'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'seu', 'seus', 'só', 'somos', 'sou', 'sua', 'suas', 'também', 'te', 'tem', 'tém', 'temos', 'tenha', 'tenham', 'tenhamos', 'tenho', 'terá', 'terão', 'terei', 'teremos', 'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tu', 'tua', 'tuas', 'um', 'uma', 'você', 'vocês', 'vos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNFbY6H1ervC"
      },
      "source": [
        "# Função de processamento do texto, tiram pontuação, letras maiúsculas, números ...\n",
        "def preprocessamento(texto):\n",
        "  texto_formatado = texto.lower()\n",
        "  tokens = []\n",
        "  for token in nltk.word_tokenize(texto_formatado):\n",
        "    tokens.append(token)\n",
        "\n",
        "  tokens = [palavra for palavra in tokens if palavra not in stopwords and palavra not in string.punctuation]\n",
        "  texto_formatado = ' '.join([str(elemento) for elemento in tokens if not elemento.isdigit()])\n",
        "\n",
        "  return texto_formatado"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "KhkaxziLctKz",
        "outputId": "bb4d642d-0380-41c0-ae25-84743c5102ab"
      },
      "source": [
        "# Texto de exemplo aplicando a formatação adequada\n",
        "texto_original = \"\"\"A inteligência artificial é a inteligência similar à humana máquinas.\n",
        "                    Definem como o estudo de agente artificial com inteligência.\n",
        "                    Ciência e engenharia de produzir máquinas com inteligência.\n",
        "                    Resolver problemas e possuir inteligência.\n",
        "                    Relacionada ao comportamento inteligente.\n",
        "                    Construção de máquinas para raciocinar.\n",
        "                    Aprender com os erros e acertos.\n",
        "                    Inteligência artificial é raciocinar nas situações do cotidiano.\"\"\"\n",
        "texto_original = re.sub(r'\\s+', ' ', texto_original)\n",
        "texto_original"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A inteligência artificial é a inteligência similar à humana máquinas. Definem como o estudo de agente artificial com inteligência. Ciência e engenharia de produzir máquinas com inteligência. Resolver problemas e possuir inteligência. Relacionada ao comportamento inteligente. Construção de máquinas para raciocinar. Aprender com os erros e acertos. Inteligência artificial é raciocinar nas situações do cotidiano.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfuFBQ06iahM"
      },
      "source": [
        "## Função para calcular a similaridade entre sentenças\n",
        "\n",
        "- Link: https://en.wikipedia.org/wiki/Cosine_similarity\n",
        "- Cálculos passo a passo: https://janav.wordpress.com/2013/10/27/tf-idf-and-cosine-similarity/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01WnGc7cUuAP"
      },
      "source": [
        "# Pegando as sentenças originais e as formatadas, como já visto\n",
        "sentencas_originais = [sentenca for sentenca in nltk.sent_tokenize(texto_original)]\n",
        "sentencas_formatadas = [preprocessamento(sentenca_original) for sentenca_original in sentencas_originais]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ywevay_CVDHg",
        "outputId": "85db78be-05d2-4e10-a622-a39b3decc9df"
      },
      "source": [
        "sentencas_originais"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A inteligência artificial é a inteligência similar à humana máquinas.',\n",
              " 'Definem como o estudo de agente artificial com inteligência.',\n",
              " 'Ciência e engenharia de produzir máquinas com inteligência.',\n",
              " 'Resolver problemas e possuir inteligência.',\n",
              " 'Relacionada ao comportamento inteligente.',\n",
              " 'Construção de máquinas para raciocinar.',\n",
              " 'Aprender com os erros e acertos.',\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGVJDvzGVFas",
        "outputId": "b9c4a804-3df1-4fc1-ae11-06d4f733f748"
      },
      "source": [
        "sentencas_formatadas"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['inteligência artificial inteligência similar humana máquinas',\n",
              " 'definem estudo agente artificial inteligência',\n",
              " 'ciência engenharia produzir máquinas inteligência',\n",
              " 'resolver problemas possuir inteligência',\n",
              " 'relacionada comportamento inteligente',\n",
              " 'construção máquinas raciocinar',\n",
              " 'aprender erros acertos',\n",
              " 'inteligência artificial raciocinar situações cotidiano']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zrNg4IZVOZX"
      },
      "source": [
        "# Função para calcular uma nota de quanto duas sentenças se parecem entre si\n",
        "def calcula_similaridade_sentencas(sentenca1, sentenca2):\n",
        "  # Tokeniza as falavras de cada sentença\n",
        "  palavras1 = [palavra for palavra in nltk.word_tokenize(sentenca1)]\n",
        "  palavras2 = [palavra for palavra in nltk.word_tokenize(sentenca2)]\n",
        "\n",
        "  # Junta as palavras únicas das duas sentenças\n",
        "  todas_palavras = list(set(palavras1 + palavras2))\n",
        "\n",
        "  # Iniciando o vetor de cada sentença no tamanho de todas as palavras com zero\n",
        "  vetor1 = [0] * len(todas_palavras)\n",
        "  vetor2 = [0] * len(todas_palavras)\n",
        "\n",
        "  # Adiciona 1 no vetor de palavra que pertence ao conjunto de cada sentença\n",
        "  for palavra in palavras1:\n",
        "    vetor1[todas_palavras.index(palavra)] += 1\n",
        "  for palavra in palavras2:\n",
        "    vetor2[todas_palavras.index(palavra)] += 1\n",
        "\n",
        "  # Retorna calculando o cosseno entre os valores nos vetores\n",
        "  return 1 - cosine_distance(vetor1, vetor2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuTRTd4KVkSI",
        "outputId": "c919c2db-e744-4001-d8eb-c15a7ab72b42"
      },
      "source": [
        "calcula_similaridade_sentencas(sentencas_formatadas[0], sentencas_formatadas[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999999999998"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrBir9vnijWB"
      },
      "source": [
        "## Função para gerar a matriz de similaridade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njeMm3ZRZ3Vo"
      },
      "source": [
        "# Função para calular a similaridade de todas com todas as sentenças\n",
        "def calcula_matriz_similaridade(sentencas):\n",
        "  matriz_similaridade = np.zeros((len(sentencas), len(sentencas)))\n",
        "\n",
        "  # Faz para cada sentença o cálculo de similarizade, SIM repete-se os valores dos triagulares superior e inferior, mas não na diagonal principal\n",
        "  for i in range(len(sentencas)):\n",
        "    for j in range(len(sentencas)):\n",
        "      if j == i:\n",
        "        continue\n",
        "      matriz_similaridade[i][j] = calcula_similaridade_sentencas(sentencas[i], sentencas[j])\n",
        "\n",
        "  return matriz_similaridade"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWM1fHxSaHrt",
        "outputId": "8f7e474b-1b2c-4d5f-ab90-6334d55207f7"
      },
      "source": [
        "calcula_matriz_similaridade(sentencas_formatadas)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.47434165, 0.47434165, 0.35355339, 0.        ,\n",
              "        0.20412415, 0.        , 0.47434165],\n",
              "       [0.47434165, 0.        , 0.2       , 0.2236068 , 0.        ,\n",
              "        0.        , 0.        , 0.4       ],\n",
              "       [0.47434165, 0.2       , 0.        , 0.2236068 , 0.        ,\n",
              "        0.25819889, 0.        , 0.2       ],\n",
              "       [0.35355339, 0.2236068 , 0.2236068 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.2236068 ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.20412415, 0.        , 0.25819889, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.25819889],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.47434165, 0.4       , 0.2       , 0.2236068 , 0.        ,\n",
              "        0.25819889, 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPYH6nUiEHQ"
      },
      "source": [
        "## Função para sumarizar\n",
        "\n",
        "- Algoritmo Page Rank: https://www.youtube.com/watch?v=YfDNI1jp5sM e https://www.youtube.com/watch?v=YplmCue8XJU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwRnuL7pbqwq"
      },
      "source": [
        "# Função de sumarização do texto, já visto em outras vezes, mas agora como o cálculo do cosseno usando a matriz se similaridade\n",
        "def sumarizar(texto, quantidade_sentencas):\n",
        "  # Separa o texto em sentenças e formata cada uma delas para depois criar a matriz de similaridade\n",
        "  sentencas_originais = [sentenca for sentenca in nltk.sent_tokenize(texto)]\n",
        "  sentencas_formatadas = [preprocessamento(sentenca_original) for sentenca_original in sentencas_originais]\n",
        "  matriz_similaridade = calcula_matriz_similaridade(sentencas_formatadas)\n",
        "\n",
        "  # Criando do grafo a partir da matriz de similaridade\n",
        "  grafo_similaridade = nx.from_numpy_array(matriz_similaridade)\n",
        "\n",
        "  # Usa o algoritmo de PageRank para calcular as notas\n",
        "  notas = nx.pagerank(grafo_similaridade)\n",
        "\n",
        "  # Ordena reversamente as notas obtidas, do maior para o menor\n",
        "  notas_ordenadas = sorted(((notas[i], nota) for i, nota in enumerate(sentencas_originais)), reverse=True)\n",
        "\n",
        "  # Faz a seleção das melhores sentenças\n",
        "  melhores_sentencas = []\n",
        "  for i in range(quantidade_sentencas):\n",
        "    melhores_sentencas.append(notas_ordenadas[i][1])\n",
        "\n",
        "  return sentencas_originais, melhores_sentencas, notas_ordenadas"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPeO-9aicU5-"
      },
      "source": [
        "sentencas_originais, melhores_sentencas, notas_sentencas = sumarizar(texto_original, 3)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptcMtccmfLK8",
        "outputId": "11185ba8-18f2-4d94-b397-e92fb0d72d84"
      },
      "source": [
        "sentencas_originais"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A inteligência artificial é a inteligência similar à humana máquinas.',\n",
              " 'Definem como o estudo de agente artificial com inteligência.',\n",
              " 'Ciência e engenharia de produzir máquinas com inteligência.',\n",
              " 'Resolver problemas e possuir inteligência.',\n",
              " 'Relacionada ao comportamento inteligente.',\n",
              " 'Construção de máquinas para raciocinar.',\n",
              " 'Aprender com os erros e acertos.',\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blQYYIanfNNc",
        "outputId": "80af8f9e-f88e-4e1f-e137-dd4902b1ffbc"
      },
      "source": [
        "melhores_sentencas"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A inteligência artificial é a inteligência similar à humana máquinas.',\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.',\n",
              " 'Ciência e engenharia de produzir máquinas com inteligência.']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrEoPcigfPQx",
        "outputId": "e0dba123-3ee2-409a-a2b4-b1d008bfb19f"
      },
      "source": [
        "notas_sentencas"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.22820924040178003,\n",
              "  'A inteligência artificial é a inteligência similar à humana máquinas.'),\n",
              " (0.1839190802151221,\n",
              "  'Inteligência artificial é raciocinar nas situações do cotidiano.'),\n",
              " (0.1633191450783496,\n",
              "  'Ciência e engenharia de produzir máquinas com inteligência.'),\n",
              " (0.1543717033327776,\n",
              "  'Definem como o estudo de agente artificial com inteligência.'),\n",
              " (0.12639273963873288, 'Resolver problemas e possuir inteligência.'),\n",
              " (0.09616903563964783, 'Construção de máquinas para raciocinar.'),\n",
              " (0.023809527846794958, 'Relacionada ao comportamento inteligente.'),\n",
              " (0.023809527846794958, 'Aprender com os erros e acertos.')]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ckhtV0Nzf4c"
      },
      "source": [
        "## Visualização do resumo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJqyBA0DhuwR"
      },
      "source": [
        "from IPython.core.display import HTML\n",
        "\n",
        "# Função para formatação e vizualização do texto destacando as melhores sentenças\n",
        "def visualiza_resumo(titulo, lista_sentencas, melhores_sentencas):\n",
        "  texto = ''\n",
        "  display(HTML(f'<h1>Resumo do texto - {titulo}</h1>'))\n",
        "\n",
        "  for sentenca in lista_sentencas:\n",
        "    if sentenca in melhores_sentencas:\n",
        "      texto += f\"<mark>{sentenca}</mark>\"\n",
        "    else:\n",
        "      texto += sentenca\n",
        "\n",
        "  display(HTML(f\"\"\" {texto} \"\"\"))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "AwPgTskpf8L0",
        "outputId": "d3c4820e-9b9c-4567-d05d-68f85cd94ee2"
      },
      "source": [
        "visualiza_resumo('Teste', sentencas_originais, melhores_sentencas)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Resumo do texto - Teste</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " <mark>A inteligência artificial é a inteligência similar à humana máquinas.</mark>Definem como o estudo de agente artificial com inteligência.<mark>Ciência e engenharia de produzir máquinas com inteligência.</mark>Resolver problemas e possuir inteligência.Relacionada ao comportamento inteligente.Construção de máquinas para raciocinar.Aprender com os erros e acertos.<mark>Inteligência artificial é raciocinar nas situações do cotidiano.</mark> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6z-C9JozqZu"
      },
      "source": [
        "## Extração de texto da internet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo97xpjxzsTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade29255-19c0-4cc9-e04b-a109602cff27"
      },
      "source": [
        "!pip install goose3"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting goose3\n",
            "  Downloading goose3-3.1.17-py3-none-any.whl (88 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m81.9/88.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from goose3) (2.31.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from goose3) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from goose3) (4.9.3)\n",
            "Collecting cssselect (from goose3)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from goose3) (4.11.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from goose3) (2.8.2)\n",
            "Collecting langdetect (from goose3)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyahocorasick (from goose3)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->goose3) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->goose3) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->goose3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->goose3) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->goose3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->goose3) (2023.11.17)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=ddc740179a44b42471440e0492ff3ab47dc702456f764e73fb74d8b0537c91ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: pyahocorasick, langdetect, cssselect, goose3\n",
            "Successfully installed cssselect-1.2.0 goose3-3.1.17 langdetect-1.0.9 pyahocorasick-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9tl7IhIzwl_"
      },
      "source": [
        "# Importando e criando o objeto para extrair textos da web\n",
        "from goose3 import Goose\n",
        "g = Goose()\n",
        "url = 'https://iaexpert.academy/2020/11/09/ia-preve-resultado-das-eleicoes-americanas/'\n",
        "artigo = g.extract(url)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "icNSs-pPzzHH",
        "outputId": "5f2dd9c9-3935-4b0c-b615-3140067a892c"
      },
      "source": [
        "artigo.cleaned_text"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.\\n\\nO modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais. O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.\\n\\nO Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores. O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual. O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la. Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho. Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado. Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.\\n\\nQuando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem. Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.\\n\\nParece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFeat1tIz4Ig"
      },
      "source": [
        "# Aplica a sumarização nesse texto\n",
        "sentencas_originais, melhores_sentencas, notas_sentencas = sumarizar(artigo.cleaned_text, 5)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VqjSb0_z6_9",
        "outputId": "b0737c5b-dc79-496d-9487-749a46e554ee"
      },
      "source": [
        "sentencas_originais"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton.',\n",
              " 'Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos.',\n",
              " 'Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados.',\n",
              " 'Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.',\n",
              " 'O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.',\n",
              " 'O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito.',\n",
              " 'No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.',\n",
              " 'O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado.',\n",
              " 'Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.',\n",
              " 'O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.',\n",
              " 'O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana.',\n",
              " 'A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.',\n",
              " 'O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.',\n",
              " 'Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.',\n",
              " 'Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.',\n",
              " 'Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.',\n",
              " 'Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.',\n",
              " 'Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.',\n",
              " 'Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C7gY7Lyz87l",
        "outputId": "d1cf7150-5aca-40f8-e279-d5cd24bc1582"
      },
      "source": [
        "melhores_sentencas"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.',\n",
              " 'Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.',\n",
              " 'No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.',\n",
              " 'Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.',\n",
              " 'O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enaQoUHI0AXF",
        "outputId": "145ff9c9-0baf-4ed6-b9b9-50578263afa8"
      },
      "source": [
        "notas_sentencas"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.10322707053208108,\n",
              "  'Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.'),\n",
              " (0.08467351062155114,\n",
              "  'Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.'),\n",
              " (0.07824901512415162,\n",
              "  'No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.'),\n",
              " (0.07627442688432466,\n",
              "  'Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.'),\n",
              " (0.07333552035097592,\n",
              "  'O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.'),\n",
              " (0.07240389589770964,\n",
              "  'Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.'),\n",
              " (0.06666298135659274,\n",
              "  'O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado.'),\n",
              " (0.06336431981938684,\n",
              "  'A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.'),\n",
              " (0.05741561693769898,\n",
              "  'Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados.'),\n",
              " (0.05697801130584347,\n",
              "  'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton.'),\n",
              " (0.04719462160210583,\n",
              "  'O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.'),\n",
              " (0.045755051094352545,\n",
              "  'Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.'),\n",
              " (0.040957901824736284,\n",
              "  'O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana.'),\n",
              " (0.027359424445456797,\n",
              "  'Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.'),\n",
              " (0.02674377415371308,\n",
              "  'Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.'),\n",
              " (0.024641096264236436,\n",
              "  'O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito.'),\n",
              " (0.024333336033629575,\n",
              "  'O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.'),\n",
              " (0.02216596294153566,\n",
              "  'Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.'),\n",
              " (0.00826446280991742,\n",
              "  'Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos.')]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "m3UMdYnc0Gwy",
        "outputId": "30d86b31-151b-4bd0-c10b-66371043191e"
      },
      "source": [
        "visualiza_resumo(artigo.title, sentencas_originais, melhores_sentencas)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Resumo do texto - IA prevê resultado das eleições americanas</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton.Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos.Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados.Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.<mark>O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.</mark>O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito.<mark>No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.</mark>O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado.<mark>Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.</mark>O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana.A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.<mark>Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.</mark>Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.<mark>Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.</mark>Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas. "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChVSxfFx1k8p"
      },
      "source": [
        "## Solução para o exercício - lematização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxRYrDAm1tFS"
      },
      "source": [
        "# Importa a biblioteca para trabalhar com vizualização e formatação de texto\n",
        "import spacy"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XIar_-510XW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0703586-05e0-45d8-ff8f-9c578ef9d4f5"
      },
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-27 00:00:45.300114: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-27 00:00:45.300201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-27 00:00:45.302254: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-27 00:00:47.599623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting pt-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.6.0/pt_core_news_sm-3.6.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.1.3)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qy5o6_G1oPU",
        "outputId": "f1e0ade4-f121-40bf-e903-507d4a8a9fd7"
      },
      "source": [
        "# Baixa os módulos em português\n",
        "pln = spacy.load(\"pt_core_news_sm\")\n",
        "pln"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.pt.Portuguese at 0x7e4fb085e2c0>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE8dBtmO15Gs"
      },
      "source": [
        "# Função já implementada anteriormente de lematização, agora usando a biblioteca spacy\n",
        "def preprocessamento_lematizacao(texto):\n",
        "  texto = texto.lower()\n",
        "  texto = re.sub(r\" +\", ' ', texto)\n",
        "\n",
        "  documento = pln(texto)\n",
        "  tokens = []\n",
        "  for token in documento:\n",
        "    tokens.append(token.lemma_)\n",
        "\n",
        "  tokens = [palavra for palavra in tokens if palavra not in stopwords and palavra not in string.punctuation]\n",
        "  texto_formatado = ' '.join([str(elemento) for elemento in tokens if not elemento.isdigit()])\n",
        "\n",
        "  return texto_formatado"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXCf0RyB1_Xm"
      },
      "source": [
        "# Função de lematização uzando os cálculos de cosseno, só que com o spacy\n",
        "def sumarizar_lematizacao(texto, quantidade_sentencas):\n",
        "  sentencas_originais = [sentenca for sentenca in nltk.sent_tokenize(texto)]\n",
        "  sentencas_formatadas = [preprocessamento_lematizacao(sentenca_original) for sentenca_original in sentencas_originais]\n",
        "  matriz_similaridade = calcula_matriz_similaridade(sentencas_formatadas)\n",
        "  grafo_similaridade = nx.from_numpy_array(matriz_similaridade)\n",
        "  notas = nx.pagerank(grafo_similaridade)\n",
        "  notas_ordenadas = sorted(((notas[i], nota) for i, nota in enumerate(sentencas_originais)), reverse=True)\n",
        "  melhores_sentencas = []\n",
        "  for i in range(quantidade_sentencas):\n",
        "    melhores_sentencas.append(notas_ordenadas[i][1])\n",
        "\n",
        "  return sentencas_originais, melhores_sentencas, notas_ordenadas"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "pAKxQnbv2IRs",
        "outputId": "bb37b171-772a-4184-da59-3bf94b7d122b"
      },
      "source": [
        "artigo.cleaned_text"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.\\n\\nO modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais. O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.\\n\\nO Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores. O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual. O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la. Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho. Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado. Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.\\n\\nQuando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem. Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.\\n\\nParece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "PChlT_gB2MsD",
        "outputId": "75e933ce-07cc-47bf-f971-fb84f51b2b6e"
      },
      "source": [
        "# Aplicando a sumarização original com o algoritmo anterior\n",
        "sentencas_originais, melhores_sentencas, _ = sumarizar(artigo.cleaned_text, 5)\n",
        "visualiza_resumo(artigo.title, sentencas_originais, melhores_sentencas)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Resumo do texto - IA prevê resultado das eleições americanas</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton.Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos.Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados.Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.<mark>O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.</mark>O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito.<mark>No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.</mark>O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado.<mark>Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.</mark>O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana.A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.<mark>Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.</mark>Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.<mark>Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.</mark>Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas. "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nv2lGNx2YI-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "da69f2d5-16c6-4ee0-b775-f1e29728265f"
      },
      "source": [
        "# Aplicando a sumarização original com o algoritmo novo com cosseno\n",
        "sentencas_originais, melhores_sentencas, _ = sumarizar_lematizacao(artigo.cleaned_text, 5)\n",
        "visualiza_resumo(artigo.title, sentencas_originais, melhores_sentencas)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Resumo do texto - IA prevê resultado das eleições americanas</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " <mark>Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton.</mark>Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos.Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados.Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.<mark>O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.</mark>O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito.<mark>No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.</mark><mark>O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado.</mark>Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana.<mark>A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.</mark>O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas. "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}