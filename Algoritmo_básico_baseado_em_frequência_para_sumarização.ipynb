{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUEq8nGVXtwL"
      },
      "source": [
        "# Algoritmo básico baseado em frequência"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCiAiO8LULAm"
      },
      "source": [
        "## Pré-processamento do texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebloqnjuIbdh"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import string"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNw0IvPjInIz"
      },
      "source": [
        "# Texto para ser analisado\n",
        "texto_original = \"\"\"A inteligência artificial é a inteligência similar à humana.\n",
        "                    Definem como o estudo de agente artificial com inteligência.\n",
        "                    Ciência e engenharia de produzir máquinas com inteligência.\n",
        "                    Resolver problemas e possuir inteligência.\n",
        "                    Relacionada ao comportamento inteligente.\n",
        "                    Construção de máquinas para raciocinar.\n",
        "                    Aprender com os erros e acertos.\n",
        "                    Inteligência artificial é raciocinar nas situações do cotidiano.\"\"\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "G-pXqhIqI85A",
        "outputId": "ed15a9eb-4df7-4d59-fb83-081eb904c00f"
      },
      "source": [
        "texto_original"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A inteligência artificial é a inteligência similar à humana.\\n                    Definem como o estudo de agente artificial com inteligência.\\n                    Ciência e engenharia de produzir máquinas com inteligência.\\n                    Resolver problemas e possuir inteligência.\\n                    Relacionada ao comportamento inteligente.\\n                    Construção de máquinas para raciocinar.\\n                    Aprender com os erros e acertos.\\n                    Inteligência artificial é raciocinar nas situações do cotidiano.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzqvD4OWJJb7"
      },
      "source": [
        "# Usa REX para tirar os espaços maiores que um\n",
        "texto_original = re.sub(r'\\s+', ' ', texto_original)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "R1HavIL9Jgfb",
        "outputId": "1454c0b0-7696-4a64-e4e9-95ce51a84a9b"
      },
      "source": [
        "texto_original"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A inteligência artificial é a inteligência similar à humana. Definem como o estudo de agente artificial com inteligência. Ciência e engenharia de produzir máquinas com inteligência. Resolver problemas e possuir inteligência. Relacionada ao comportamento inteligente. Construção de máquinas para raciocinar. Aprender com os erros e acertos. Inteligência artificial é raciocinar nas situações do cotidiano.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDXCPV_5KyUZ",
        "outputId": "39a81a27-eb58-4ce0-d257-1ee71fd568b6"
      },
      "source": [
        "# Download da função para tokenização (partição) da biblioteca nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idHTfn9ALKWR",
        "outputId": "98fd63c6-d2c5-4d47-cf72-815ea5a1975a"
      },
      "source": [
        "# Download da função para achar as stopwords da biblioteca nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9fQjEGWLQ2P",
        "outputId": "9c3fc4c4-74e3-445a-cff8-809da4122d60"
      },
      "source": [
        "# Mostras as stopwords da língua portuguesa\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "print(stopwords)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'às', 'até', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois', 'do', 'dos', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram', 'éramos', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estou', 'eu', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'formos', 'fosse', 'fossem', 'fôssemos', 'fui', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'haver', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'lhe', 'lhes', 'mais', 'mas', 'me', 'mesmo', 'meu', 'meus', 'minha', 'minhas', 'muito', 'na', 'não', 'nas', 'nem', 'no', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os', 'ou', 'para', 'pela', 'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando', 'que', 'quem', 'são', 'se', 'seja', 'sejam', 'sejamos', 'sem', 'ser', 'será', 'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'seu', 'seus', 'só', 'somos', 'sou', 'sua', 'suas', 'também', 'te', 'tem', 'tém', 'temos', 'tenha', 'tenham', 'tenhamos', 'tenho', 'terá', 'terão', 'terei', 'teremos', 'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tu', 'tua', 'tuas', 'um', 'uma', 'você', 'vocês', 'vos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyVB90mGLiSY",
        "outputId": "67b989b4-79f9-425f-825d-ac18fd3d7876"
      },
      "source": [
        "# Quantidade de stopwords na língua portuguesa\n",
        "len(stopwords)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "207"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iH4acUY4MGEP",
        "outputId": "c8bfb064-8517-40ff-8af8-ada5ff723898"
      },
      "source": [
        "# As pontuações da biblioteca string (ASCII)\n",
        "string.punctuation"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxw-AMecJ-LZ"
      },
      "source": [
        "# Função para pré-processar o texto em minúsculo e retirar as stopwords do texto de entrada\n",
        "def preprocessamento(texto):\n",
        "  # Passa para minúsculo\n",
        "  texto_formatado = texto.lower()\n",
        "\n",
        "  # Cria o array vazio que conterá cada palavra do texto de entrada\n",
        "  tokens = []\n",
        "\n",
        "  # Adiciona cada palavra do texto de entrada no array tokens\n",
        "  for token in nltk.word_tokenize(texto_formatado):\n",
        "    tokens.append(token)\n",
        "\n",
        "  # Toda palavra que não estiver nas stopwords do texto original e não for pontuação são conservadas no array\n",
        "  tokens = [palavra for palavra in tokens if palavra not in stopwords and palavra not in string.punctuation]\n",
        "  # Concatena as palavras restantes em um único texto\n",
        "  texto_formatado = ' '.join([str(elemento) for elemento in tokens if not elemento.isdigit()])\n",
        "\n",
        "  return texto_formatado"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "AsfdoqN7KJcS",
        "outputId": "d7a13d28-c12a-4983-bf2f-35fb5250f982"
      },
      "source": [
        "texto_formatado = preprocessamento(texto_original)\n",
        "texto_formatado"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'inteligência artificial inteligência similar humana definem estudo agente artificial inteligência ciência engenharia produzir máquinas inteligência resolver problemas possuir inteligência relacionada comportamento inteligente construção máquinas raciocinar aprender erros acertos inteligência artificial raciocinar situações cotidiano'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9qp7RfhZAaK"
      },
      "source": [
        "## Frequência das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfreeT-MNd9B",
        "outputId": "4435d6bc-a977-4f2d-d91f-ad7c5173b374"
      },
      "source": [
        "# Calcula a frequência das palavras, ou seja, a quantidade de vezes que cada uma aparece no texto\n",
        "frequencia_palavras = nltk.FreqDist(nltk.word_tokenize(texto_formatado))\n",
        "frequencia_palavras"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'inteligência': 6, 'artificial': 3, 'máquinas': 2, 'raciocinar': 2, 'similar': 1, 'humana': 1, 'definem': 1, 'estudo': 1, 'agente': 1, 'ciência': 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz7QsG0jN9_p",
        "outputId": "18ec18a3-4a55-47a1-c12e-961f50fff175"
      },
      "source": [
        "# Acessando uma plavra específica\n",
        "frequencia_palavras['situações']"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ZAmlrXOLcd",
        "outputId": "86ce03e1-a34a-463d-b8e5-c0ba64ba925a"
      },
      "source": [
        "# Somente as palavras, chaves do dicionário\n",
        "frequencia_palavras.keys()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['inteligência', 'artificial', 'similar', 'humana', 'definem', 'estudo', 'agente', 'ciência', 'engenharia', 'produzir', 'máquinas', 'resolver', 'problemas', 'possuir', 'relacionada', 'comportamento', 'inteligente', 'construção', 'raciocinar', 'aprender', 'erros', 'acertos', 'situações', 'cotidiano'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpzgxTMhOqw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5d3aed-eacc-4bb5-ec8b-dc5866b534e8"
      },
      "source": [
        "# O maior número de vezes que aparece uma palavra\n",
        "frequencia_maxima = max(frequencia_palavras.values())\n",
        "frequencia_maxima"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DObCdFaxO0od",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d19dc8f-b7e7-4437-f23a-733bdfe5b491"
      },
      "source": [
        "# Cálculo da requência proporcional do aparecimento das palavras (pesos) [A cada execução acontece a divisão CUIDADO!!!]\n",
        "for palavra in frequencia_palavras.keys():\n",
        "  print('%s - %f/%f = %f' %(palavra, frequencia_palavras[palavra], frequencia_maxima, frequencia_palavras[palavra] / frequencia_maxima))\n",
        "  frequencia_palavras[palavra] = (frequencia_palavras[palavra] / frequencia_maxima)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inteligência - 6.000000/6.000000 = 1.000000\n",
            "artificial - 3.000000/6.000000 = 0.500000\n",
            "similar - 1.000000/6.000000 = 0.166667\n",
            "humana - 1.000000/6.000000 = 0.166667\n",
            "definem - 1.000000/6.000000 = 0.166667\n",
            "estudo - 1.000000/6.000000 = 0.166667\n",
            "agente - 1.000000/6.000000 = 0.166667\n",
            "ciência - 1.000000/6.000000 = 0.166667\n",
            "engenharia - 1.000000/6.000000 = 0.166667\n",
            "produzir - 1.000000/6.000000 = 0.166667\n",
            "máquinas - 2.000000/6.000000 = 0.333333\n",
            "resolver - 1.000000/6.000000 = 0.166667\n",
            "problemas - 1.000000/6.000000 = 0.166667\n",
            "possuir - 1.000000/6.000000 = 0.166667\n",
            "relacionada - 1.000000/6.000000 = 0.166667\n",
            "comportamento - 1.000000/6.000000 = 0.166667\n",
            "inteligente - 1.000000/6.000000 = 0.166667\n",
            "construção - 1.000000/6.000000 = 0.166667\n",
            "raciocinar - 2.000000/6.000000 = 0.333333\n",
            "aprender - 1.000000/6.000000 = 0.166667\n",
            "erros - 1.000000/6.000000 = 0.166667\n",
            "acertos - 1.000000/6.000000 = 0.166667\n",
            "situações - 1.000000/6.000000 = 0.166667\n",
            "cotidiano - 1.000000/6.000000 = 0.166667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frequencia_palavras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7_GHpxTBohl",
        "outputId": "4af5a5a0-1685-4a1a-d642-4c120ed77e46"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'inteligência': 1.0, 'artificial': 0.5, 'máquinas': 0.3333333333333333, 'raciocinar': 0.3333333333333333, 'similar': 0.16666666666666666, 'humana': 0.16666666666666666, 'definem': 0.16666666666666666, 'estudo': 0.16666666666666666, 'agente': 0.16666666666666666, 'ciência': 0.16666666666666666, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SKF87yAZ3iW"
      },
      "source": [
        "## Tokenização de sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD5DqdcyPokT",
        "outputId": "9f76b1fb-19d3-496b-cfd6-3c013cd1e824"
      },
      "source": [
        "# Quebrando uma frase com ponto (Maneira errada)\n",
        "'o dr. joão foi para casa. Ele chegou cedo'.split('.')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['o dr', ' joão foi para casa', ' Ele chegou cedo']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiAe588tP-GC",
        "outputId": "620ee773-4cc5-4be1-8ae2-696331db8e32"
      },
      "source": [
        "# Tokenizando cada lavra, como já visto\n",
        "nltk.word_tokenize('o dr. joão foi para casa. Ele chegou cedo')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['o', 'dr.', 'joão', 'foi', 'para', 'casa', '.', 'Ele', 'chegou', 'cedo']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJC_Bjq0QLBP",
        "outputId": "48990d58-49b1-4d8e-d205-f0452cbc0ec8"
      },
      "source": [
        "# Tokenizando frases (sentenças)\n",
        "nltk.sent_tokenize('o dr. joão foi para casa. Ele chegou cedo')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['o dr. joão foi para casa.', 'Ele chegou cedo']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqCsJlSEQX8n",
        "outputId": "b4614973-19a2-4074-ba2f-d78a2897e6d2"
      },
      "source": [
        "# Fazendo a tokenização de sentenças para o texto original\n",
        "lista_sentencas = nltk.sent_tokenize(texto_original)\n",
        "lista_sentencas"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A inteligência artificial é a inteligência similar à humana.',\n",
              " 'Definem como o estudo de agente artificial com inteligência.',\n",
              " 'Ciência e engenharia de produzir máquinas com inteligência.',\n",
              " 'Resolver problemas e possuir inteligência.',\n",
              " 'Relacionada ao comportamento inteligente.',\n",
              " 'Construção de máquinas para raciocinar.',\n",
              " 'Aprender com os erros e acertos.',\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zNS8EciaQuC"
      },
      "source": [
        "## Geração do resumo (nota para as sentenças)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgO5vlO_T0oO",
        "outputId": "15af2c58-698a-4a01-c0c4-f4c6a8eef2cb"
      },
      "source": [
        "# Frenquẽncia já calculada das palavras\n",
        "frequencia_palavras"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'inteligência': 1.0, 'artificial': 0.5, 'máquinas': 0.3333333333333333, 'raciocinar': 0.3333333333333333, 'similar': 0.16666666666666666, 'humana': 0.16666666666666666, 'definem': 0.16666666666666666, 'estudo': 0.16666666666666666, 'agente': 0.16666666666666666, 'ciência': 0.16666666666666666, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria um dicionário, tendo com chaves as sentenças e inicialmente com valor zero\n",
        "nota_sentencas = dict.fromkeys(lista_sentencas, 0)\n",
        "\n",
        "# Passa por cada frase verificando as palavras e somando o peso para cada sentença\n",
        "for sentenca in lista_sentencas:\n",
        "  for palavra in nltk.word_tokenize(sentenca.lower()):\n",
        "    if palavra in frequencia_palavras.keys():\n",
        "        nota_sentencas[sentenca] += frequencia_palavras[palavra]"
      ],
      "metadata": {
        "id": "k3N2Yd9rHjWt"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q32tttLVWnl",
        "outputId": "40de0f00-504a-4208-e526-198795f30b5c"
      },
      "source": [
        "nota_sentencas"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A inteligência artificial é a inteligência similar à humana.': 2.833333333333333,\n",
              " 'Definem como o estudo de agente artificial com inteligência.': 2.0,\n",
              " 'Ciência e engenharia de produzir máquinas com inteligência.': 1.8333333333333333,\n",
              " 'Resolver problemas e possuir inteligência.': 1.5,\n",
              " 'Relacionada ao comportamento inteligente.': 0.5,\n",
              " 'Construção de máquinas para raciocinar.': 0.8333333333333333,\n",
              " 'Aprender com os erros e acertos.': 0.5,\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.': 2.1666666666666665}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uma maneira de ordenar decrescentemente por valor o dicionário\n",
        "dict(sorted(nota_sentencas.items(), key=lambda item: item[1], reverse=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh9sFS4_JoDD",
        "outputId": "e130c0cc-ed70-426c-e24b-fe29f0f79535"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A inteligência artificial é a inteligência similar à humana.': 2.833333333333333,\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.': 2.1666666666666665,\n",
              " 'Definem como o estudo de agente artificial com inteligência.': 2.0,\n",
              " 'Ciência e engenharia de produzir máquinas com inteligência.': 1.8333333333333333,\n",
              " 'Resolver problemas e possuir inteligência.': 1.5,\n",
              " 'Construção de máquinas para raciocinar.': 0.8333333333333333,\n",
              " 'Relacionada ao comportamento inteligente.': 0.5,\n",
              " 'Aprender com os erros e acertos.': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L1SeNy4Vnah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0801fb39-23fb-4b4d-f76c-d6623a10444e"
      },
      "source": [
        "import heapq\n",
        "\n",
        "# Busca as 3 melhores sentenças (mais pontuadas) no dicionário\n",
        "melhores_sentencas = heapq.nlargest(3, nota_sentencas, key=nota_sentencas.get)\n",
        "melhores_sentencas"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A inteligência artificial é a inteligência similar à humana.',\n",
              " 'Inteligência artificial é raciocinar nas situações do cotidiano.',\n",
              " 'Definem como o estudo de agente artificial com inteligência.']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TB0-dAzlWRwV",
        "outputId": "60f41775-588b-4405-b595-f86f741f034f"
      },
      "source": [
        "# Concatena as 3 sentenças com maiores notas em uma único texto\n",
        "resumo = ' '.join(melhores_sentencas)\n",
        "resumo"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A inteligência artificial é a inteligência similar à humana. Inteligência artificial é raciocinar nas situações do cotidiano. Definem como o estudo de agente artificial com inteligência.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qkw5lFjGWZWa",
        "outputId": "d32b0ab9-6b9f-4869-f8db-e3fed490b96f"
      },
      "source": [
        "# Comparalção o texto original\n",
        "texto_original"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A inteligência artificial é a inteligência similar à humana. Definem como o estudo de agente artificial com inteligência. Ciência e engenharia de produzir máquinas com inteligência. Resolver problemas e possuir inteligência. Relacionada ao comportamento inteligente. Construção de máquinas para raciocinar. Aprender com os erros e acertos. Inteligência artificial é raciocinar nas situações do cotidiano.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C05hd_M5c4yr"
      },
      "source": [
        "## Visualização do resumo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "GT7PCH1CW3Vg",
        "outputId": "e456867f-17af-4318-e768-f4532a9b67e0"
      },
      "source": [
        "# Uma maneira de mostrar o texto com realce nas frases mais pontuadas\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "texto = ''\n",
        "\n",
        "# Título\n",
        "display(HTML(f'<h1>Resumo do texto</h1>'))\n",
        "\n",
        "# Percorre a lista de sentenças e identifica as mais pontias e mostra elas de outras forma\n",
        "for sentenca in lista_sentencas:\n",
        "  texto += f\"<mark>{sentenca}</mark>\" if sentenca in melhores_sentencas else sentenca\n",
        "\n",
        "# Resultado\n",
        "display(HTML(f\"\"\"{texto}\"\"\"))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Resumo do texto</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<mark>A inteligência artificial é a inteligência similar à humana.</mark><mark>Definem como o estudo de agente artificial com inteligência.</mark>Ciência e engenharia de produzir máquinas com inteligência.Resolver problemas e possuir inteligência.Relacionada ao comportamento inteligente.Construção de máquinas para raciocinar.Aprender com os erros e acertos.<mark>Inteligência artificial é raciocinar nas situações do cotidiano.</mark>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ0aG69oUxc2"
      },
      "source": [
        "## Extração de texto da internet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypDK-KpDY4pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b61d8a7-2245-4449-c3b4-c8caf5f5f75e"
      },
      "source": [
        "!pip install goose3"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting goose3\n",
            "  Downloading goose3-3.1.17-py3-none-any.whl (88 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from goose3) (2.31.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from goose3) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from goose3) (4.9.3)\n",
            "Collecting cssselect (from goose3)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from goose3) (4.11.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from goose3) (2.8.2)\n",
            "Collecting langdetect (from goose3)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyahocorasick (from goose3)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->goose3) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->goose3) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->goose3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->goose3) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->goose3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->goose3) (2023.11.17)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=600884bd7a6dc74bdbe3efa23819c280b73075b9b037fd2754523291a664037d\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: pyahocorasick, langdetect, cssselect, goose3\n",
            "Successfully installed cssselect-1.2.0 goose3-3.1.17 langdetect-1.0.9 pyahocorasick-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tieDeYNJZC06"
      },
      "source": [
        "# Chamando a biblioteca de extração de texto da internet\n",
        "from goose3 import Goose"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTS2OxXCZFy6"
      },
      "source": [
        "# Acessa uma página para obter as informação dela\n",
        "g = Goose()\n",
        "url = 'https://iaexpert.academy/2020/11/09/ia-preve-resultado-das-eleicoes-americanas/'\n",
        "artigo = g.extract(url)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pNEH9YaZTva",
        "outputId": "496af5b9-d11b-4569-f052-b377c1183baa"
      },
      "source": [
        "artigo.infos"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'meta': {'description': '',\n",
              "  'lang': 'pt',\n",
              "  'keywords': '',\n",
              "  'favicon': 'https://cdn.shortpixel.ai/spai/q_+ret_img+to_webp/https://iaexpert.academy/wp-content/uploads/2020/06/cropped-favicon-1-32x32.png',\n",
              "  'canonical': 'https://iaexpert.academy/2020/11/09/ia-preve-resultado-das-eleicoes-americanas/',\n",
              "  'encoding': 'UTF-8'},\n",
              " 'image': None,\n",
              " 'domain': 'iaexpert.academy',\n",
              " 'title': 'IA prevê resultado das eleições americanas',\n",
              " 'cleaned_text': 'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.\\n\\nO modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais. O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.\\n\\nO Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores. O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual. O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la. Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho. Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado. Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.\\n\\nQuando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem. Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.\\n\\nParece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.',\n",
              " 'opengraph': {'locale': 'pt_BR',\n",
              "  'type': 'article',\n",
              "  'title': 'IA prevê resultado das eleições americanas | IA Expert Academy',\n",
              "  'description': 'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização … IA prevê resultado das eleições americanas Leia mais »',\n",
              "  'url': 'https://iaexpert.academy/2020/11/09/ia-preve-resultado-das-eleicoes-americanas/',\n",
              "  'site_name': 'IA Expert Academy',\n",
              "  'article:publisher': 'https://pt-br.facebook.com/iaexpert/',\n",
              "  'article:published_time': '2020-11-09T08:00:00+00:00',\n",
              "  'article:modified_time': '2020-11-07T14:47:25+00:00',\n",
              "  'image': 'https://iaexpert.academy/wp-content/uploads/2020/11/vote.jpg',\n",
              "  'image:width': '800',\n",
              "  'image:height': '450',\n",
              "  'image:type': 'image/jpeg'},\n",
              " 'tags': [],\n",
              " 'tweets': [],\n",
              " 'movies': [],\n",
              " 'links': ['https://www.ccny.cuny.edu/profiles/hernan-makse',\n",
              "  'https://www.express.co.uk/news/science/1355192/artificial-intelligence-ai-news-twitter-us-election-2020-prediction-trump-biden-evg'],\n",
              " 'authors': ['Denny Ceccon'],\n",
              " 'publish_date': '2020-11-09T08:00:00+00:00'}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UcmsoTinZggK",
        "outputId": "a62450e7-f94c-464c-b8e7-68cf8de82163"
      },
      "source": [
        "# Título da página\n",
        "artigo.title"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'IA prevê resultado das eleições americanas'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vokH5XcBZlfX",
        "outputId": "e0e3e475-6524-4503-907a-77ecd6ea9503"
      },
      "source": [
        "# Links da página\n",
        "artigo.links"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://www.ccny.cuny.edu/profiles/hernan-makse',\n",
              " 'https://www.express.co.uk/news/science/1355192/artificial-intelligence-ai-news-twitter-us-election-2020-prediction-trump-biden-evg']"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyN6CkMxZoLg",
        "outputId": "b35aef69-2bdf-457a-83a0-5d0ff98d034f"
      },
      "source": [
        "# Se houver tags\n",
        "artigo.tags"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "d5330LEeZy9E",
        "outputId": "05674393-2e84-4d8a-a1f3-61cb0a621045"
      },
      "source": [
        "# Atribui o texto principal da página\n",
        "artigo_original = artigo.cleaned_text\n",
        "artigo_original"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.\\n\\nO modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais. O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.\\n\\nO Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores. O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual. O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la. Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho. Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado. Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.\\n\\nQuando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem. Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.\\n\\nParece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "y_Py0p-tZ5o9",
        "outputId": "b08eb593-7b6f-44fc-d072-47c77cf43ae7"
      },
      "source": [
        "# Passa o texto da página na função de préprocessamento\n",
        "artigo_formatado = preprocessamento(artigo_original)\n",
        "artigo_formatado"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eleições presidenciais americanas maioria predições apontavam vitória hillary clinton entretanto história mostrou resultado oposto donald trump presidente últimos anos desta vez estatísticos reexaminaram modelos aumentar grau confiabilidade resultados nesta tentativa otimização predições inteligência artificial certamente ficou modelo desenvolvido dr. hernan makse físico estatístico universidade cidade nova york baseou predições rede neural treinada processar sentimentos expressos redes sociais algoritmo fez análise cerca bilhão tweets chegar estimativa resultados pleito dia eleição novembro modelo indicando vitória joe biden dr. makse disse trabalho começou eleição testado novamente eleições argentina ano passado desta vez modelo treinando cerca vezes dados eleições americanas anteriores trabalho depende apenas coleta dados tratamento estatístico adequado levar consideração duas variáveis externas viés amostragem taxa comparecimento primeiro fator refere fato redes sociais necessariamente representam população americana participação redes sociais costuma maior cidades grandes fato têm preferência candidatos modelo deve corrigido levar consideração opinião pessoas ativas neste ambiente virtual segundo fator deve não-obrigatoriedade votação estados unidos pessoa preferência pode compareça locais votação efetivá-la segundo dr. makse integrar duas variáveis modelo parte importante trabalho acredita razões estimativas última eleição baseadas métodos tradicionais coleta informação terem falhado equipe acompanhou tendências apresentadas últimas eleições europa modelos revelando cada vez melhores modelo usado predizer resultados eleição corrente usando dados brutos joe biden apareceu vencedor larga vantagem após aplicar mecanismos correção dois vieses identificados vantagem diminuiu biden ainda indicado favorito parece desta vez algoritmos fato contribuindo predições precisas'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qz2wttDaGvw",
        "outputId": "871d7e6c-f795-451a-cd14-b5359ad0fbeb"
      },
      "source": [
        "# Comparando o tamanho dos textos\n",
        "print('Original: %d\\nProcessado: %d' %(len(artigo_formatado), len(artigo.cleaned_text)))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: 1901\n",
            "Processado: 2638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH6ykNXfaZQM"
      },
      "source": [
        "# Função das partes já vistas, somente para facilitar e fazer tudo de uma vez só\n",
        "def sumarizar(texto, quantidade_sentencas):\n",
        "  texto_original = texto\n",
        "  texto_formatado = preprocessamento(texto_original)\n",
        "\n",
        "  frequencia_palavras = nltk.FreqDist(nltk.word_tokenize(texto_formatado))\n",
        "  frequencia_maxima = max(frequencia_palavras.values())\n",
        "  for palavra in frequencia_palavras.keys():\n",
        "    frequencia_palavras[palavra] = (frequencia_palavras[palavra] / frequencia_maxima)\n",
        "  lista_sentencas = nltk.sent_tokenize(texto_original)\n",
        "\n",
        "  nota_sentencas = dict.fromkeys(lista_sentencas, 0)\n",
        "  for sentenca in lista_sentencas:\n",
        "    for palavra in nltk.word_tokenize(sentenca.lower()):\n",
        "      if palavra in frequencia_palavras.keys():\n",
        "          nota_sentencas[sentenca] += frequencia_palavras[palavra]\n",
        "\n",
        "  melhores_sentencas = heapq.nlargest(quantidade_sentencas, nota_sentencas, key=nota_sentencas.get)\n",
        "\n",
        "  return lista_sentencas, melhores_sentencas, frequencia_palavras, nota_sentencas"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ2u4sRlbMu_"
      },
      "source": [
        "# Chamando essa função para reber os valores de retorno\n",
        "lista_sentencas, melhores_sentencas, frequencia_palavras, nota_sentencas = sumarizar(artigo_original, 5)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q2hDAqjbY35",
        "outputId": "9f0e5c50-4186-45ee-c121-19bfdc917447"
      },
      "source": [
        "lista_sentencas, len(lista_sentencas)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton.',\n",
              "  'Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos.',\n",
              "  'Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados.',\n",
              "  'Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.',\n",
              "  'O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.',\n",
              "  'O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito.',\n",
              "  'No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.',\n",
              "  'O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado.',\n",
              "  'Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.',\n",
              "  'O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.',\n",
              "  'O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana.',\n",
              "  'A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.',\n",
              "  'O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.',\n",
              "  'Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.',\n",
              "  'Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.',\n",
              "  'Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.',\n",
              "  'Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.',\n",
              "  'Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.',\n",
              "  'Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.'],\n",
              " 19)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNxwneSlboHy",
        "outputId": "c4e64ded-24e8-4366-b47a-d0e85d02c748"
      },
      "source": [
        "melhores_sentencas"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.',\n",
              " 'A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.',\n",
              " 'Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.',\n",
              " 'O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.',\n",
              " 'Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.']"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYg3hpBpbwR2",
        "outputId": "e127b7d8-34fc-4490-8b0c-67955d4e90ff"
      },
      "source": [
        "frequencia_palavras"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'modelo': 1.0, 'eleições': 0.6666666666666666, 'predições': 0.6666666666666666, 'vez': 0.6666666666666666, 'eleição': 0.6666666666666666, 'desta': 0.5, 'resultados': 0.5, 'dr.': 0.5, 'makse': 0.5, 'redes': 0.5, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68knBIpacblW",
        "outputId": "bb7b77a2-2d3d-4423-923a-9d4617a1c10e"
      },
      "source": [
        "nota_sentencas"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton.': 2.833333333333333,\n",
              " 'Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos.': 1.6666666666666667,\n",
              " 'Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados.': 2.833333333333333,\n",
              " 'Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.': 1.8333333333333335,\n",
              " 'O modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais.': 6.333333333333335,\n",
              " 'O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito.': 2.1666666666666665,\n",
              " 'No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.': 3.3333333333333335,\n",
              " 'O Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado.': 3.999999999999999,\n",
              " 'Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.': 4.5,\n",
              " 'O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.': 4.500000000000001,\n",
              " 'O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana.': 2.8333333333333326,\n",
              " 'A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.': 6.166666666666668,\n",
              " 'O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la.': 3.333333333333333,\n",
              " 'Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.': 3.9999999999999996,\n",
              " 'Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado.': 2.6666666666666665,\n",
              " 'Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.': 3.166666666666666,\n",
              " 'Quando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem.': 5.166666666666667,\n",
              " 'Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.': 2.666666666666666,\n",
              " 'Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.': 2.9999999999999996}"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEHelL-tc3Nh"
      },
      "source": [
        "# Função para formatação das sentenças, como já visto\n",
        "def visualiza_resumo(titulo, lista_sentencas, melhores_sentencas):\n",
        "  texto = ''\n",
        "\n",
        "  display(HTML(f'<h1>{titulo}</h1>'))\n",
        "\n",
        "  for sentenca in lista_sentencas:\n",
        "    texto += f\"<mark>{sentenca}</mark>\" if sentenca in melhores_sentencas else sentenca\n",
        "\n",
        "  display(HTML(f\"\"\"{texto}\"\"\"))"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "6WteYBEhdIqV",
        "outputId": "1d82ecac-8932-45f2-d428-e29df0ba9e2d"
      },
      "source": [
        "visualiza_resumo(artigo.title, lista_sentencas, melhores_sentencas)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>AutoML: aspectos e aplicações</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Os algoritmos de machine learning são métodos numéricos implementados na forma de linguagem de programação, para que sejam processados por computadores.<mark>Estes métodos são formulados de forma que o algoritmo resolva um problema não através da sua modelagem matemática, que exigiria o conhecimento de uma equação específica que descreve o problema, mas sim através de um modelo mais genérico, capaz de aproximar a equação desconhecida, e que por um processo iterativo tende a convergir para uma solução.</mark>Seu grande sucesso se deve ao fato de que os computadores são ideais para implementar estas iterações, já que elas são blocos de operações matemáticas mais simples que se repetem até que a solução seja alcançada.Através das iterações, os algoritmos ajustam seus parâmetros internos de forma que o modelo seja capaz de reproduzir as respostas do problema a partir dos dados de entrada.É assim que os modelos de machine learning ganham a capacidade de fazer predições em novos dados.Apesar de o processo descrito acima ser automatizado, existem alguns parâmetros que, via de regra, não podem ser ajustados de maneira automática.Isto se deve principalmente ao fato de que não existe uma relação matemática precisa entre estes parâmetros e o desempenho do modelo, para que eles possam ser ajustados computacionalmente na direção da melhor solução.Além disso, eles costumam ser independentes entre si, de forma que diferentes combinações de valores de hiperparâmetros produzem resultados sem relação entre si, e pode ser que a solução ideal resida num espaço bastante distante de outras soluções adequadas.Os hiperparâmetros, que incluem a escolha do modelo e seus ajustes específicos, costumam ser configurados manualmente pelo desenvolvedor, que só vai saber sua qualidade ao final do processo de treinamento, avaliando as métricas de desempenho.O sucesso em sua escolha vai depender do conhecimento que o desenvolvedor tem sobre os dados com que está trabalhando, sua experiência em utilizar e ajustar os diferentes algoritmos disponíveis, e ainda uma boa dose de sorte.Mais recentemente, surgiram algumas bibliotecas buscando automatizar esta etapa inerentemente exploratória do processo de desenvolvimento de algoritmos de machine learning.Elas funcionam basicamente testando diferentes valores de hiperparâmetros e suas combinações, orientados por alguma heurística que estabelece uma direção para esta busca, retornando o desempenho do modelo nestas diferentes situações.Se por um lado esta abordagem ignora a intuição do desenvolvedor na escolha dos hiperparâmetros a serem testados, por outro ela poupa tempo que o desenvolvedor gastaria escrevendo código, e agora pode dispender em outras tarefas.A bem da verdade, há vantagens e desvantagens na sua utilização, além de fases específicas de um projeto onde elas podem ser de grande utilidade.Quando um cientista de dados inicia um novo projeto, é essencial desenvolver rapidamente uma ideia sobre sua viabilidade, já que, em uma empresa, o principal objetivo deste profissional é entregar valor.<mark>Como a natureza dos dados começa geralmente desconhecida, usar ferramentas de machine learning automático nesta fase inicial ajuda a estabelecer uma ideia mínima sobre o custo de oportunidade do projeto.</mark>Os modelos gerados desta forma podem servir como baseline, estabelecendo o desempenho mínimo possível a partir do qual a empresa pode decidir se a ideia toda vale a pena, se é sensato investir mais tempo e recursos para tentar melhorar este panorama inicial.O AutoML nesta fase inicial também ajuda a definir um cenário geral a ser explorado.Digamos que a abordagem revele que os melhores modelos são de uma determinada família de métodos numéricos.Então, é possível que os processos de otimização seguintes sejam melhor sucedidos se continuarem a exploração neste sentido.Assim, o cientista de dados já pula uma fase longa do desenvolvimento, podendo focar sua atenção na compreensão das tarefas mais específicas que o método de AutoML não é capaz de realizar.Outra grande vantagem de recorrer a métodos de AutoML é quando a empresa está em transição para ser um negócio orientado por dados.Nesta fase, ela ainda pode estar reticente sobre desenvolver toda uma nova área, estabelecer toda uma nova cultura, e o AutoML fornece uma indicação para responder se é hora de tomar essa decisão.Em muitas situações, faz mais sentido reciclar um desenvolvedor interno da empresa para fazer este estudo inicial do que contratar um profissional específico, com conhecimento técnico suficiente, para obter a mesma resposta.Diante da possibilidade de otimizar modelos usando ferramentas automáticas, muitos se perguntam se ainda há espaço para os cientistas de dados que faziam este trabalho manualmente.Mas certamente há.<mark>O AutoML ainda é incapaz de incorporar conhecimento que não seja facilmente expresso em operações matemáticas simples; ele não faz, por exemplo, as etapas de e análise causal, não resolve situações de , não considera como a escolha do modelo impacta a fase de produção do projeto, e não incorpora aspectos relacionados ao negócio.</mark>Pode ser que o AutoML encontre uma solução inviável em termos práticos.É papel do cientista de dados refinar seus resultados.<mark>De fato, a menor parte do tempo de um cientista de dados é gasta escrevendo código e desenvolvendo modelos; sua expertise está muito mais relacionada em como conectar o conhecimento oriundo dos dados com suas aplicações no mundo real.</mark>Ao invés de um concorrente, o AutoML é mais uma ferramenta que o cientista de dados dispõe, que automatiza uma parte mais braçal de seu trabalho para que ele possa se concentrar nas tarefas mais complexas.Alguns de seus pontos fortes disponíveis ao cientista de dados são: geração de baselines confiáveis e consistentes, aumento da reprodutibilidade e da robustez metodológica, disponibilidade de várias heurísticas de treinamento, e maior possibilidade de experimentação.A seguir apresentamos algumas das bibliotecas mais citadas atualmente.Fazendo uso da extensa coleção de métodos do Scikit-Learn, temos a e a , que fazem uma busca no espaço de soluções usando otimização bayesiana.A se baseia em um pipeline que busca valores de hiperparâmetros usando uma abordagem baseada em árvore de decisão.A permite a otimização de redes neurais construídas usando o Keras.A pesquisa os melhores parâmetros para modelos baseados em árvores de decisão e redes neurais.Via de regra, estas bibliotecas são extremamente fáceis de implementar.A ideia geral é fornecer os dados e alguns limitantes como o tempo disponível para rodar a otimização.Muito prático, não?Assim como várias tarefas de outras profissões vão sendo substituídas por métodos automatizados, algumas atribuições do cientista de dados também são passíveis de passar por esta transformação.Mas a ciência de dados tem muito a ganhar com o uso das ferramentas de AutoML, explorando seus pontos fortes e deixando os profissionais livres para trabalharem em seus pontos fracos.<mark>No final do dia, o AutoML é uma ferramenta poderosa disponível no arsenal do cientista de dados, mas ainda assim apenas uma ferramenta, que precisa de um operador para coordenar como esta pequena parte do trabalho vai integrar com o todo.</mark>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FuLiqlkqP-V"
      },
      "source": [
        "## Sumarização de mais textos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjnIZwpNe85B"
      },
      "source": [
        "# Outras páginas para fazer sumarização\n",
        "lista_artigos = ['https://iaexpert.academy/2020/11/06/ia-detecta-deep-fakes-produzidos-com-tecnicas-recentes/',\n",
        "                 'https://iaexpert.academy/2020/11/13/facebook-apresenta-novo-algoritmo-deteccao-fake-news/',\n",
        "                 'https://iaexpert.academy/2020/11/16/automl-aspectos-aplicacoes/']"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "woglfEn5fLLk",
        "outputId": "c1f85047-e75c-42e4-972d-21504f482e1b"
      },
      "source": [
        "# Fazendo as sumarização para cada página\n",
        "for url in lista_artigos:\n",
        "  g = Goose()\n",
        "  artigo = g.extract(url)\n",
        "  lista_sentencas, melhores_sentencas, _, _ = sumarizar(artigo.cleaned_text, 5)\n",
        "  visualiza_resumo(artigo.title, lista_sentencas, melhores_sentencas)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>IA detecta deep fakes produzidos com as técnicas mais recentes</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<mark>No ano passado, pesquisadores da Universidade de Stanford publicaram um trabalho descrevendo uma tecnologia para sincronização de lábios que permitia que editores de vídeo pudessem alterar as palavras de quem está falando de forma quase imperceptível, o que permitia inserir ou remover palavras mesmo no meio de frases.</mark>A tecnologia tem aplicações benéficas, como durante a edição de filmes, onde não seria necessário refilmar sequências ou fazer malabarismos de montagem para que o resultado final ficasse de acordo com a vontade do diretor.Entretanto, ela também poderia ser utilizada com más intenções, como para produzir deep fakes com conteúdo desinformativo.Este ano, os mesmos pesquisadores apresentaram um novo trabalho capaz de detectar as alterações realizadas.<mark>Ele se baseia nas mesmas ideias desenvolvidas no trabalho anterior, que buscavam parear fonemas com o que eles chamaram de “visemas”, correspondentes à posição dos lábios durante a produção do fonema.</mark><mark>Apesar de as edições produzidas terem passado despercebidas por avaliadores humanos, ainda assim alguns artefatos são inseridos, sobretudo em fonemas com visemas bem característicos, como aqueles das letras M, B e P. Nestes casos, os lábios devem se fechar de forma firme.</mark>Pequenas diferenças entre as representações reais e criadas destes visemas foram utilizadas para detectar as sessões editadas dos vídeos com o uso de uma rede neural convolucional.No trabalho, os cientistas avaliaram vários vídeos adulterados do ex-presidente Barack Obama.O algoritmo, treinado com instâncias deste dataset, conseguiu identificar os casos de deep fake com precisão superior a 90%.Quando avaliado em um dataset mais amplo contendo outras pessoas, a precisão foi de 81%.<mark>Os autores comentam que detecções de deep fake com manipulação espacial e temporal limitada, como as edições feitas para alterar sutilmente um discurso de forma a mudar sua interpretação, são particularmente difíceis de detectar.</mark>Em casos de alto risco, a avaliação pode ser feita por uma pessoa qualificada, mas num ambiente mais amplo, técnicas automáticas são necessárias.<mark>Neste sentido, seu trabalho é um avanço importante no combate às más práticas associadas a esta tecnologia, já que apresenta resultados promissores avaliando deep fakes criados com as técnicas mais recentes.</mark>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Facebook apresenta novo algoritmo para detecção de fake news</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Já é de amplo reconhecimento que as redes sociais afetaram o panorama político nos países com eleições.<mark>Se por um lado, as plataformas permitem a disseminação de ideias e programas políticos, permitindo uma maior divulgação de candidatos menos populares, por outro, agentes mal-intencionados têm usado as redes para disseminar fake news e assim manipular as eleições em seu favor.</mark>Em função de todo este poder, nos últimos anos tem aumentado a pressão para que empresas como Facebook e Twitter tomem medidas de forma a amenizar os efeitos nocivos que suas plataformas podem ter.<mark>Em agosto deste ano, o Facebook apresentou na Conferência de Data Mining e Descoberta de Conhecimento ( ) um trabalho detalhando um modelo implementado pela empresa para, como diz o título do artigo, “melhorar a integridade da rede social”.</mark><mark>O modelo faz uso de uma nova abstração chamada de ( ), que foi desenvolvida com o objetivo de reconhecer interações sociais “rebeldes” para que elas possam ser encaminhadas para tratamento individualizado.</mark>O modelo tem a estrutura de uma rede neural, treinado de forma supervisionada, e incorpora características estáticas e dinâmicas das chamadas entidades sociais.<mark>Isso quer dizer que, ao contrários dos métodos anteriores que focavam em apenas um desses aspectos – por exemplo, o histórico de postagem ou a lista de amigos das contas -, o novo algoritmo leva ambos em consideração, “desmontando” as interações em partes como quem esteve envolvido, e o que e onde aconteceu.</mark><mark>Isso foi possível graças à evolução recente nos domínios de embeddings de grafos, usados para representar interações em uma rede, e de aprendizagem de comportamento sequencial profunda, capaz de classificar a intenção de um agente através da consistência de seu comportamento.</mark>O resultado é uma compreensão mais detalhada sobre a natureza da conta e das postagens, que permite um controle mais fino dos moderadores.No artigo, o Facebook demonstrou o uso da ferramenta na prevenção da disseminação de fake news e na detecção de contas falsas.A abordagem certamente tem suas limitações.Em primeiro lugar, por se tratar de um problema supervisionado, instâncias devem ser rotuladas por pessoal técnico antes do treinamento, e nem sempre é fácil classificar um comportamento como malicioso.Em segundo, a ferramenta apenas identifica situações suspeitas, mas o plano de ação continua sendo delegado a um moderador, dependendo de avaliações de natureza bastante subjetiva.Mas há de se reconhecer os esforços da empresa em assumir responsabilidade pelo uso indevido da sua plataforma.Além de controlar o fluxo de informações falsas, as empresas pretendem manter a confiança em suas plataformas, para garantir que o ambiente mantenha sua percepção como saudável, construtivo e convidativo aos usuários."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>AutoML: aspectos e aplicações</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Os algoritmos de machine learning são métodos numéricos implementados na forma de linguagem de programação, para que sejam processados por computadores.<mark>Estes métodos são formulados de forma que o algoritmo resolva um problema não através da sua modelagem matemática, que exigiria o conhecimento de uma equação específica que descreve o problema, mas sim através de um modelo mais genérico, capaz de aproximar a equação desconhecida, e que por um processo iterativo tende a convergir para uma solução.</mark>Seu grande sucesso se deve ao fato de que os computadores são ideais para implementar estas iterações, já que elas são blocos de operações matemáticas mais simples que se repetem até que a solução seja alcançada.Através das iterações, os algoritmos ajustam seus parâmetros internos de forma que o modelo seja capaz de reproduzir as respostas do problema a partir dos dados de entrada.É assim que os modelos de machine learning ganham a capacidade de fazer predições em novos dados.Apesar de o processo descrito acima ser automatizado, existem alguns parâmetros que, via de regra, não podem ser ajustados de maneira automática.Isto se deve principalmente ao fato de que não existe uma relação matemática precisa entre estes parâmetros e o desempenho do modelo, para que eles possam ser ajustados computacionalmente na direção da melhor solução.Além disso, eles costumam ser independentes entre si, de forma que diferentes combinações de valores de hiperparâmetros produzem resultados sem relação entre si, e pode ser que a solução ideal resida num espaço bastante distante de outras soluções adequadas.Os hiperparâmetros, que incluem a escolha do modelo e seus ajustes específicos, costumam ser configurados manualmente pelo desenvolvedor, que só vai saber sua qualidade ao final do processo de treinamento, avaliando as métricas de desempenho.O sucesso em sua escolha vai depender do conhecimento que o desenvolvedor tem sobre os dados com que está trabalhando, sua experiência em utilizar e ajustar os diferentes algoritmos disponíveis, e ainda uma boa dose de sorte.Mais recentemente, surgiram algumas bibliotecas buscando automatizar esta etapa inerentemente exploratória do processo de desenvolvimento de algoritmos de machine learning.Elas funcionam basicamente testando diferentes valores de hiperparâmetros e suas combinações, orientados por alguma heurística que estabelece uma direção para esta busca, retornando o desempenho do modelo nestas diferentes situações.Se por um lado esta abordagem ignora a intuição do desenvolvedor na escolha dos hiperparâmetros a serem testados, por outro ela poupa tempo que o desenvolvedor gastaria escrevendo código, e agora pode dispender em outras tarefas.A bem da verdade, há vantagens e desvantagens na sua utilização, além de fases específicas de um projeto onde elas podem ser de grande utilidade.Quando um cientista de dados inicia um novo projeto, é essencial desenvolver rapidamente uma ideia sobre sua viabilidade, já que, em uma empresa, o principal objetivo deste profissional é entregar valor.<mark>Como a natureza dos dados começa geralmente desconhecida, usar ferramentas de machine learning automático nesta fase inicial ajuda a estabelecer uma ideia mínima sobre o custo de oportunidade do projeto.</mark>Os modelos gerados desta forma podem servir como baseline, estabelecendo o desempenho mínimo possível a partir do qual a empresa pode decidir se a ideia toda vale a pena, se é sensato investir mais tempo e recursos para tentar melhorar este panorama inicial.O AutoML nesta fase inicial também ajuda a definir um cenário geral a ser explorado.Digamos que a abordagem revele que os melhores modelos são de uma determinada família de métodos numéricos.Então, é possível que os processos de otimização seguintes sejam melhor sucedidos se continuarem a exploração neste sentido.Assim, o cientista de dados já pula uma fase longa do desenvolvimento, podendo focar sua atenção na compreensão das tarefas mais específicas que o método de AutoML não é capaz de realizar.Outra grande vantagem de recorrer a métodos de AutoML é quando a empresa está em transição para ser um negócio orientado por dados.Nesta fase, ela ainda pode estar reticente sobre desenvolver toda uma nova área, estabelecer toda uma nova cultura, e o AutoML fornece uma indicação para responder se é hora de tomar essa decisão.Em muitas situações, faz mais sentido reciclar um desenvolvedor interno da empresa para fazer este estudo inicial do que contratar um profissional específico, com conhecimento técnico suficiente, para obter a mesma resposta.Diante da possibilidade de otimizar modelos usando ferramentas automáticas, muitos se perguntam se ainda há espaço para os cientistas de dados que faziam este trabalho manualmente.Mas certamente há.<mark>O AutoML ainda é incapaz de incorporar conhecimento que não seja facilmente expresso em operações matemáticas simples; ele não faz, por exemplo, as etapas de e análise causal, não resolve situações de , não considera como a escolha do modelo impacta a fase de produção do projeto, e não incorpora aspectos relacionados ao negócio.</mark>Pode ser que o AutoML encontre uma solução inviável em termos práticos.É papel do cientista de dados refinar seus resultados.<mark>De fato, a menor parte do tempo de um cientista de dados é gasta escrevendo código e desenvolvendo modelos; sua expertise está muito mais relacionada em como conectar o conhecimento oriundo dos dados com suas aplicações no mundo real.</mark>Ao invés de um concorrente, o AutoML é mais uma ferramenta que o cientista de dados dispõe, que automatiza uma parte mais braçal de seu trabalho para que ele possa se concentrar nas tarefas mais complexas.Alguns de seus pontos fortes disponíveis ao cientista de dados são: geração de baselines confiáveis e consistentes, aumento da reprodutibilidade e da robustez metodológica, disponibilidade de várias heurísticas de treinamento, e maior possibilidade de experimentação.A seguir apresentamos algumas das bibliotecas mais citadas atualmente.Fazendo uso da extensa coleção de métodos do Scikit-Learn, temos a e a , que fazem uma busca no espaço de soluções usando otimização bayesiana.A se baseia em um pipeline que busca valores de hiperparâmetros usando uma abordagem baseada em árvore de decisão.A permite a otimização de redes neurais construídas usando o Keras.A pesquisa os melhores parâmetros para modelos baseados em árvores de decisão e redes neurais.Via de regra, estas bibliotecas são extremamente fáceis de implementar.A ideia geral é fornecer os dados e alguns limitantes como o tempo disponível para rodar a otimização.Muito prático, não?Assim como várias tarefas de outras profissões vão sendo substituídas por métodos automatizados, algumas atribuições do cientista de dados também são passíveis de passar por esta transformação.Mas a ciência de dados tem muito a ganhar com o uso das ferramentas de AutoML, explorando seus pontos fortes e deixando os profissionais livres para trabalharem em seus pontos fracos.<mark>No final do dia, o AutoML é uma ferramenta poderosa disponível no arsenal do cientista de dados, mas ainda assim apenas uma ferramenta, que precisa de um operador para coordenar como esta pequena parte do trabalho vai integrar com o todo.</mark>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfjD0iDBrhFv"
      },
      "source": [
        "## Solução para o exercício - lematização"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "#!pip install spacy==2.2.3 #Atualizado 18/05/2021 - Utilizar essa versão"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BZSiSJqa2y_",
        "outputId": "27606286-7168-4a36-c3e7-888a00fe565d"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHO-HkYrr3vM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bae2fea-5ff5-474b-926f-ffb02b517b40"
      },
      "source": [
        "# Baixando a parte em português\n",
        "!python -m spacy download pt_core_news_sm"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-25 14:47:02.536452: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-25 14:47:02.536515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-25 14:47:02.537440: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-25 14:47:03.792924: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting pt-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.6.0/pt_core_news_sm-3.6.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a biblioteca para para lematização e a parte em português\n",
        "import spacy\n",
        "from spacy.lang.pt.examples import sentences"
      ],
      "metadata": {
        "id": "3-6F9wE5bawi"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h14a6fx6r-ko",
        "outputId": "2ef71c65-2f49-4673-d42e-5c3370e26d6f"
      },
      "source": [
        "# Carregando a parte em português\n",
        "pln = spacy.load('pt_core_news_sm')\n",
        "pln"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.pt.Portuguese at 0x7ba3a13d6200>"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I41np1BHsP12",
        "outputId": "e9769548-e467-4b6e-c2ce-eadcec46220c"
      },
      "source": [
        "# Fazendo o teste para extrair a lematização das palavras\n",
        "documento = pln('inteligentes inteligente inteligência corrida corrido correr correndo correstes')\n",
        "for token in documento:\n",
        "  print(token.text, token.lemma_)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inteligentes inteligente\n",
            "inteligente inteligente\n",
            "inteligência inteligência\n",
            "corrida corrida\n",
            "corrido correr\n",
            "correr correr\n",
            "correndo correr\n",
            "correstes correste\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odttSEcUuRSA"
      },
      "source": [
        "# Juntando o processamento e a lematização em uma mesma função\n",
        "def preprocessamento_lematizacao(texto):\n",
        "  texto = texto.lower()\n",
        "  texto = re.sub(r\" +\", ' ', texto)\n",
        "\n",
        "  documento = pln(texto)\n",
        "  tokens = []\n",
        "  for token in documento:\n",
        "    tokens.append(token.lemma_)\n",
        "\n",
        "  tokens = [palavra for palavra in tokens if palavra not in stopwords and palavra not in string.punctuation]\n",
        "  texto_formatado = ' '.join([str(elemento) for elemento in tokens if not elemento.isdigit()])\n",
        "\n",
        "  return texto_formatado"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zc3ZxNo_upTg",
        "outputId": "0e4d04ce-8fa1-4013-9d56-2b84cf6b758c"
      },
      "source": [
        "preprocessamento_lematizacao(texto_original)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'inteligência artificial inteligência similar a o humana definem estudo agente artificial inteligência ciência engenharia produzir máquina inteligência resolver problema possuir inteligência relacionar a o comportamento inteligente construção máquina raciocinar aprender erro acerto inteligência artificial raciocinar em o situação de o cotidiano'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YX62nb12u6FD",
        "outputId": "cf5d05e0-a964-4f60-ea00-f013729afeae"
      },
      "source": [
        "texto_original"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A inteligência artificial é a inteligência similar à humana. Definem como o estudo de agente artificial com inteligência. Ciência e engenharia de produzir máquinas com inteligência. Resolver problemas e possuir inteligência. Relacionada ao comportamento inteligente. Construção de máquinas para raciocinar. Aprender com os erros e acertos. Inteligência artificial é raciocinar nas situações do cotidiano.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb7uhMwxvNc4"
      },
      "source": [
        "# Agora sumarizando e fazendo a lematização numa mesma fução\n",
        "def sumarizar_lematizacao(texto, quantidade_sentencas):\n",
        "  texto_original = texto\n",
        "  texto_formatado = preprocessamento_lematizacao(texto_original)\n",
        "\n",
        "  frequencia_palavras = nltk.FreqDist(nltk.word_tokenize(texto_formatado))\n",
        "  frequencia_maxima = max(frequencia_palavras.values())\n",
        "  for palavra in frequencia_palavras.keys():\n",
        "    frequencia_palavras[palavra] = (frequencia_palavras[palavra] / frequencia_maxima)\n",
        "  lista_sentencas = nltk.sent_tokenize(texto_original)\n",
        "\n",
        "  nota_sentencas = dict.fromkeys(lista_sentencas, 0)\n",
        "  for sentenca in lista_sentencas:\n",
        "    for palavra in nltk.word_tokenize(sentenca.lower()):\n",
        "      if palavra in frequencia_palavras.keys():\n",
        "          nota_sentencas[sentenca] += frequencia_palavras[palavra]\n",
        "\n",
        "  melhores_sentencas = heapq.nlargest(quantidade_sentencas, nota_sentencas, key=nota_sentencas.get)\n",
        "\n",
        "  return lista_sentencas, melhores_sentencas, frequencia_palavras, nota_sentencas"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AGyBRVNwwXdJ",
        "outputId": "4cc7abf6-f65b-42e9-b4c9-61332e4381a1"
      },
      "source": [
        "# Fazendo o mesmo resumo da lista de artigos anteriormente\n",
        "for url in lista_artigos:\n",
        "  g = Goose()\n",
        "  artigo = g.extract(url)\n",
        "  lista_sentencas, melhores_sentencas, _, _ = sumarizar_lematizacao(artigo.cleaned_text, 5)\n",
        "  visualiza_resumo(artigo.title, lista_sentencas, melhores_sentencas)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>IA detecta deep fakes produzidos com as técnicas mais recentes</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<mark>No ano passado, pesquisadores da Universidade de Stanford publicaram um trabalho descrevendo uma tecnologia para sincronização de lábios que permitia que editores de vídeo pudessem alterar as palavras de quem está falando de forma quase imperceptível, o que permitia inserir ou remover palavras mesmo no meio de frases.</mark><mark>A tecnologia tem aplicações benéficas, como durante a edição de filmes, onde não seria necessário refilmar sequências ou fazer malabarismos de montagem para que o resultado final ficasse de acordo com a vontade do diretor.</mark>Entretanto, ela também poderia ser utilizada com más intenções, como para produzir deep fakes com conteúdo desinformativo.Este ano, os mesmos pesquisadores apresentaram um novo trabalho capaz de detectar as alterações realizadas.<mark>Ele se baseia nas mesmas ideias desenvolvidas no trabalho anterior, que buscavam parear fonemas com o que eles chamaram de “visemas”, correspondentes à posição dos lábios durante a produção do fonema.</mark><mark>Apesar de as edições produzidas terem passado despercebidas por avaliadores humanos, ainda assim alguns artefatos são inseridos, sobretudo em fonemas com visemas bem característicos, como aqueles das letras M, B e P. Nestes casos, os lábios devem se fechar de forma firme.</mark>Pequenas diferenças entre as representações reais e criadas destes visemas foram utilizadas para detectar as sessões editadas dos vídeos com o uso de uma rede neural convolucional.No trabalho, os cientistas avaliaram vários vídeos adulterados do ex-presidente Barack Obama.O algoritmo, treinado com instâncias deste dataset, conseguiu identificar os casos de deep fake com precisão superior a 90%.Quando avaliado em um dataset mais amplo contendo outras pessoas, a precisão foi de 81%.<mark>Os autores comentam que detecções de deep fake com manipulação espacial e temporal limitada, como as edições feitas para alterar sutilmente um discurso de forma a mudar sua interpretação, são particularmente difíceis de detectar.</mark>Em casos de alto risco, a avaliação pode ser feita por uma pessoa qualificada, mas num ambiente mais amplo, técnicas automáticas são necessárias.Neste sentido, seu trabalho é um avanço importante no combate às más práticas associadas a esta tecnologia, já que apresenta resultados promissores avaliando deep fakes criados com as técnicas mais recentes."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Facebook apresenta novo algoritmo para detecção de fake news</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Já é de amplo reconhecimento que as redes sociais afetaram o panorama político nos países com eleições.Se por um lado, as plataformas permitem a disseminação de ideias e programas políticos, permitindo uma maior divulgação de candidatos menos populares, por outro, agentes mal-intencionados têm usado as redes para disseminar fake news e assim manipular as eleições em seu favor.Em função de todo este poder, nos últimos anos tem aumentado a pressão para que empresas como Facebook e Twitter tomem medidas de forma a amenizar os efeitos nocivos que suas plataformas podem ter.<mark>Em agosto deste ano, o Facebook apresentou na Conferência de Data Mining e Descoberta de Conhecimento ( ) um trabalho detalhando um modelo implementado pela empresa para, como diz o título do artigo, “melhorar a integridade da rede social”.</mark><mark>O modelo faz uso de uma nova abstração chamada de ( ), que foi desenvolvida com o objetivo de reconhecer interações sociais “rebeldes” para que elas possam ser encaminhadas para tratamento individualizado.</mark>O modelo tem a estrutura de uma rede neural, treinado de forma supervisionada, e incorpora características estáticas e dinâmicas das chamadas entidades sociais.<mark>Isso quer dizer que, ao contrários dos métodos anteriores que focavam em apenas um desses aspectos – por exemplo, o histórico de postagem ou a lista de amigos das contas -, o novo algoritmo leva ambos em consideração, “desmontando” as interações em partes como quem esteve envolvido, e o que e onde aconteceu.</mark><mark>Isso foi possível graças à evolução recente nos domínios de embeddings de grafos, usados para representar interações em uma rede, e de aprendizagem de comportamento sequencial profunda, capaz de classificar a intenção de um agente através da consistência de seu comportamento.</mark>O resultado é uma compreensão mais detalhada sobre a natureza da conta e das postagens, que permite um controle mais fino dos moderadores.No artigo, o Facebook demonstrou o uso da ferramenta na prevenção da disseminação de fake news e na detecção de contas falsas.A abordagem certamente tem suas limitações.Em primeiro lugar, por se tratar de um problema supervisionado, instâncias devem ser rotuladas por pessoal técnico antes do treinamento, e nem sempre é fácil classificar um comportamento como malicioso.Em segundo, a ferramenta apenas identifica situações suspeitas, mas o plano de ação continua sendo delegado a um moderador, dependendo de avaliações de natureza bastante subjetiva.Mas há de se reconhecer os esforços da empresa em assumir responsabilidade pelo uso indevido da sua plataforma.<mark>Além de controlar o fluxo de informações falsas, as empresas pretendem manter a confiança em suas plataformas, para garantir que o ambiente mantenha sua percepção como saudável, construtivo e convidativo aos usuários.</mark>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>AutoML: aspectos e aplicações</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Os algoritmos de machine learning são métodos numéricos implementados na forma de linguagem de programação, para que sejam processados por computadores.<mark>Estes métodos são formulados de forma que o algoritmo resolva um problema não através da sua modelagem matemática, que exigiria o conhecimento de uma equação específica que descreve o problema, mas sim através de um modelo mais genérico, capaz de aproximar a equação desconhecida, e que por um processo iterativo tende a convergir para uma solução.</mark>Seu grande sucesso se deve ao fato de que os computadores são ideais para implementar estas iterações, já que elas são blocos de operações matemáticas mais simples que se repetem até que a solução seja alcançada.Através das iterações, os algoritmos ajustam seus parâmetros internos de forma que o modelo seja capaz de reproduzir as respostas do problema a partir dos dados de entrada.É assim que os modelos de machine learning ganham a capacidade de fazer predições em novos dados.Apesar de o processo descrito acima ser automatizado, existem alguns parâmetros que, via de regra, não podem ser ajustados de maneira automática.Isto se deve principalmente ao fato de que não existe uma relação matemática precisa entre estes parâmetros e o desempenho do modelo, para que eles possam ser ajustados computacionalmente na direção da melhor solução.Além disso, eles costumam ser independentes entre si, de forma que diferentes combinações de valores de hiperparâmetros produzem resultados sem relação entre si, e pode ser que a solução ideal resida num espaço bastante distante de outras soluções adequadas.Os hiperparâmetros, que incluem a escolha do modelo e seus ajustes específicos, costumam ser configurados manualmente pelo desenvolvedor, que só vai saber sua qualidade ao final do processo de treinamento, avaliando as métricas de desempenho.O sucesso em sua escolha vai depender do conhecimento que o desenvolvedor tem sobre os dados com que está trabalhando, sua experiência em utilizar e ajustar os diferentes algoritmos disponíveis, e ainda uma boa dose de sorte.Mais recentemente, surgiram algumas bibliotecas buscando automatizar esta etapa inerentemente exploratória do processo de desenvolvimento de algoritmos de machine learning.Elas funcionam basicamente testando diferentes valores de hiperparâmetros e suas combinações, orientados por alguma heurística que estabelece uma direção para esta busca, retornando o desempenho do modelo nestas diferentes situações.Se por um lado esta abordagem ignora a intuição do desenvolvedor na escolha dos hiperparâmetros a serem testados, por outro ela poupa tempo que o desenvolvedor gastaria escrevendo código, e agora pode dispender em outras tarefas.A bem da verdade, há vantagens e desvantagens na sua utilização, além de fases específicas de um projeto onde elas podem ser de grande utilidade.Quando um cientista de dados inicia um novo projeto, é essencial desenvolver rapidamente uma ideia sobre sua viabilidade, já que, em uma empresa, o principal objetivo deste profissional é entregar valor.Como a natureza dos dados começa geralmente desconhecida, usar ferramentas de machine learning automático nesta fase inicial ajuda a estabelecer uma ideia mínima sobre o custo de oportunidade do projeto.Os modelos gerados desta forma podem servir como baseline, estabelecendo o desempenho mínimo possível a partir do qual a empresa pode decidir se a ideia toda vale a pena, se é sensato investir mais tempo e recursos para tentar melhorar este panorama inicial.O AutoML nesta fase inicial também ajuda a definir um cenário geral a ser explorado.Digamos que a abordagem revele que os melhores modelos são de uma determinada família de métodos numéricos.Então, é possível que os processos de otimização seguintes sejam melhor sucedidos se continuarem a exploração neste sentido.<mark>Assim, o cientista de dados já pula uma fase longa do desenvolvimento, podendo focar sua atenção na compreensão das tarefas mais específicas que o método de AutoML não é capaz de realizar.</mark>Outra grande vantagem de recorrer a métodos de AutoML é quando a empresa está em transição para ser um negócio orientado por dados.Nesta fase, ela ainda pode estar reticente sobre desenvolver toda uma nova área, estabelecer toda uma nova cultura, e o AutoML fornece uma indicação para responder se é hora de tomar essa decisão.Em muitas situações, faz mais sentido reciclar um desenvolvedor interno da empresa para fazer este estudo inicial do que contratar um profissional específico, com conhecimento técnico suficiente, para obter a mesma resposta.Diante da possibilidade de otimizar modelos usando ferramentas automáticas, muitos se perguntam se ainda há espaço para os cientistas de dados que faziam este trabalho manualmente.Mas certamente há.<mark>O AutoML ainda é incapaz de incorporar conhecimento que não seja facilmente expresso em operações matemáticas simples; ele não faz, por exemplo, as etapas de e análise causal, não resolve situações de , não considera como a escolha do modelo impacta a fase de produção do projeto, e não incorpora aspectos relacionados ao negócio.</mark>Pode ser que o AutoML encontre uma solução inviável em termos práticos.É papel do cientista de dados refinar seus resultados.De fato, a menor parte do tempo de um cientista de dados é gasta escrevendo código e desenvolvendo modelos; sua expertise está muito mais relacionada em como conectar o conhecimento oriundo dos dados com suas aplicações no mundo real.<mark>Ao invés de um concorrente, o AutoML é mais uma ferramenta que o cientista de dados dispõe, que automatiza uma parte mais braçal de seu trabalho para que ele possa se concentrar nas tarefas mais complexas.</mark><mark>Alguns de seus pontos fortes disponíveis ao cientista de dados são: geração de baselines confiáveis e consistentes, aumento da reprodutibilidade e da robustez metodológica, disponibilidade de várias heurísticas de treinamento, e maior possibilidade de experimentação.</mark>A seguir apresentamos algumas das bibliotecas mais citadas atualmente.Fazendo uso da extensa coleção de métodos do Scikit-Learn, temos a e a , que fazem uma busca no espaço de soluções usando otimização bayesiana.A se baseia em um pipeline que busca valores de hiperparâmetros usando uma abordagem baseada em árvore de decisão.A permite a otimização de redes neurais construídas usando o Keras.A pesquisa os melhores parâmetros para modelos baseados em árvores de decisão e redes neurais.Via de regra, estas bibliotecas são extremamente fáceis de implementar.A ideia geral é fornecer os dados e alguns limitantes como o tempo disponível para rodar a otimização.Muito prático, não?Assim como várias tarefas de outras profissões vão sendo substituídas por métodos automatizados, algumas atribuições do cientista de dados também são passíveis de passar por esta transformação.Mas a ciência de dados tem muito a ganhar com o uso das ferramentas de AutoML, explorando seus pontos fortes e deixando os profissionais livres para trabalharem em seus pontos fracos.No final do dia, o AutoML é uma ferramenta poderosa disponível no arsenal do cientista de dados, mas ainda assim apenas uma ferramenta, que precisa de um operador para coordenar como esta pequena parte do trabalho vai integrar com o todo."
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}